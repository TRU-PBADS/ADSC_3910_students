# Project requirements

In this course, you will be working on a data science project in a group of 3-4 students. The main goal of the project is to showcase the application of MongDB, PySpark, and data optimization techniques that you have learned in other courses in this term, on a real dataset. 

While we are generally open and flexible with the dataset and topic of your interest, there are a few "hard" requirements that I would like you to follow:

## 1. Data format

You should aim to work with datasets in `JSON` format, instead of `csv`. The rationale behind this requirement is to help you feel comfortable working with non-tabular, non-SQL like datasets that you have probably worked with in most previous projects. Working on a JSON format will help you extend your toolkit as a data scientist, and it also provides a nice pathway to integrate the data into MongoDB. 

### Data sources

There are many JSON data collection that you could find on the Internet (e.g., kaggle, hugging face, government sources, etc.), here's a useful [list of JSON datasets](https://dadroit.com/blog/json-datasets/) that you could use as a starting point: https://dadroit.com/blog/json-datasets/

## 2. Data science techniques and tools

- You are required to utilize MongoDB to set up a non-SQL database so that you can retrieve it into Python (using PyMongo for instance)
- You are required to incorporate PySpark in your pipeline, it could be data pre-processing, feature engineering, or ML modelling, etc. 
- You are required to integrate at least one concept from ADSC 3040: Simulations for Modelling, Optimizing, and Analysis

## 3. Final product

- A Github repository with full instruction on how to reproduce the analysis.
- A final report that highlight the methods and results
- An oral presentation that summarize the findings

**Note**
- You don't have to perform complex machine learning, or deep learning modelling in this project. Please **use your time wisely** to focus your effort on meeting the requirements above, which is to **showcase your understanding and application of MongoDB, PySpark, and Simulations techniques in your data analysis**.